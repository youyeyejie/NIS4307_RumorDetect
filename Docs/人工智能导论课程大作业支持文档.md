# 人工智能导论课程大作业支持文档

## 环境配置

建议使用anaconda/miniconda进行环境管理（可选）。

版本要求如下：
```
python>3.0.0
pytorch<2.0.0 (如果需要)
```
推荐版本：
```
python==3.8
pytorch==1.8.2 (如果需要)
```

1. （可选）安装Conda，参考[官网](https://www.anaconda.com/download).
2. 使用Conda安装python或者通过[官网](https://www.python.org/downloads/)安装.
3. 安装pytorch，参考[官网](https://pytorch.org/get-started/previous-versions/).

## 数据集下载

谣言检测数据集通过交大云盘下载（训练集和验证集），链接：https://pan.sjtu.edu.cn/web/share/29e5413f8a3ac4ff5f797660c52478da 

数据集文件内容:

\- train.csv: 训练集数据，表头为id,text,label,event，其中：id表示推文id，text表示推文内容，label中0代表非谣言，1代表谣言 ，event表示内容主题类别
\- val.csv：验证集数据

## 接口类说明

接口类文件classify.py，实现了接口类RumourDetectClass。接口类提供一个接口函数classify，该函数的输入是一条字符串，输出是一个int值（值为对应的预测类别，即整数0或1，0代表非谣言、1代表谣言）。
在接口函数中自行实现模型加载、模型推理等逻辑。如使用GPU，请用单卡运行，并加载到0号卡上。

```python
class RumourDetectClass:
    def __init__(self, ...):
        # 加载模型、设置参数等
        ...

    def misc(self, ...):
        # 其他处理函数
        ...

    def classify(self, text: str) -> int:
        # 谣言分类
        ...
        return pred_class
```

## 参考代码
#### 1. 使用逻辑回归

```python
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import joblib

# 读取数据
train_df = pd.read_csv('../dataset/split/train.csv')
val_df = pd.read_csv('../dataset/split/val.csv')

# 特征和标签
X_train = train_df['text']
y_train = train_df['label']
X_val = val_df['text']
y_val = val_df['label']

# 文本预处理
X_train = X_train.str.lower().str.replace('[^\w\s]', '', regex=True)
X_val = X_val.str.lower().str.replace('[^\w\s]', '', regex=True)

# 文本向量化（TF-IDF）
vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)
X_train_vec = vectorizer.fit_transform(X_train)
X_val_vec = vectorizer.transform(X_val)

# 逻辑回归模型
model = LogisticRegression(max_iter=1000)
model.fit(X_train_vec, y_train)

# 验证集评估
val_pred = model.predict(X_val_vec)
val_acc = accuracy_score(y_val, val_pred)
print(f'Val Acc: {val_acc:.4f}')
print(classification_report(y_val, val_pred))

# 保存模型和向量器
joblib.dump({'model': model, 'vectorizer': vectorizer}, 'lr_model.pkl')
print('模型已保存为lr_model.pkl')
```



#### 2. 使用GRU训练

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from collections import Counter
import re

# 超参数设置
BATCH_SIZE = 32
EMBEDDING_DIM = 100
HIDDEN_DIM = 128
EPOCHS = 10
MAX_LEN = 64
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# 简单分词器
def tokenize(text):
    return re.findall(r'\w+', text.lower())

# 构建词表
def build_vocab(texts, min_freq=2):
    counter = Counter()
    for text in texts:
        counter.update(tokenize(text))
    vocab = {'<PAD>': 0, '<UNK>': 1}
    idx = 2
    for w, c in counter.items():
        if c >= min_freq:
            vocab[w] = idx
            idx += 1
    return vocab

def encode(text, vocab):
    tokens = tokenize(text)
    ids = [vocab.get(t, vocab['<UNK>']) for t in tokens]
    if len(ids) < MAX_LEN:
        ids += [vocab['<PAD>']] * (MAX_LEN - len(ids))
    else:
        ids = ids[:MAX_LEN]
    return ids

class RumorDataset(Dataset):
    # 谣言数据集，返回文本和标签
    def __init__(self, df, vocab):
        self.texts = df['text'].tolist()
        self.labels = df['label'].tolist()
        self.vocab = vocab

    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        x = torch.tensor(encode(self.texts[idx], self.vocab), dtype=torch.long)
        y = torch.tensor(self.labels[idx], dtype=torch.float)
        return x, y

class BiGRU(nn.Module):
    # BiGRU模型定义
    def __init__(self, vocab_size, embedding_dim, hidden_dim):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.bigru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_dim*2, 1)

    def forward(self, x):
        # 前向传播
        emb = self.embedding(x)
        _, h = self.bigru(emb)
        h = torch.cat([h[0], h[1]], dim=1)
        out = self.fc(h)
        return out.squeeze(1)

def evaluate(model, loader):
    # 评估函数，返回准确率
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            logits = model(x)
            preds = (torch.sigmoid(logits) > 0.5).float()
            correct += (preds == y).sum().item()
            total += y.size(0)
    return correct / total

def main():
    # 读取数据集
    train_df = pd.read_csv('../dataset/split/train.csv')
    val_df = pd.read_csv('../dataset/split/val.csv')

    # 构建词表
    vocab = build_vocab(train_df['text'])
    # 构建数据集
    train_set = RumorDataset(train_df, vocab)
    val_set = RumorDataset(val_df, vocab)

    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)
    # 初始化模型、优化器和损失函数
    model = BiGRU(len(vocab), EMBEDDING_DIM, HIDDEN_DIM).to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    criterion = nn.BCEWithLogitsLoss()
    # 训练模型
    for epoch in range(EPOCHS):
        model.train()
        for x, y in train_loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            logits = model(x)
            loss = criterion(logits, y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        val_acc = evaluate(model, val_loader)
        print(f'Epoch {epoch+1}, Val Acc: {val_acc:.4f}')
        
    # 保存模型checkpoint
    torch.save(model.state_dict(), 'bigru.pt')
    print('模型已保存为bigru.pt')

if __name__ == '__main__':
    main() 
```



#### 3. classify.py例子

这里是使用逻辑回归模型作为例子
```python
import joblib
import re

class RumourDetectClass:
    def __init__(self):
        # 加载模型和vectorizer
        model_data = joblib.load('lr_model.pkl')
        self.model = model_data['model']
        self.vectorizer = model_data['vectorizer']

    def preprocess(self, text):
        # 与训练时一致的小写和去标点
        text = text.lower()
        text = re.sub(r'[^\w\s]', '', text)
        return text

    def classify(self, text: str) -> int:
        """
        对输入的文本进行谣言检测
        Args:
            text: 输入的文本字符串
        Returns:
            int: 预测的类别（0表示非谣言，1表示谣言）
        """
        text = self.preprocess(text)
        X_vec = self.vectorizer.transform([text])
        pred = self.model.predict(X_vec)[0]
        return int(pred)
```
